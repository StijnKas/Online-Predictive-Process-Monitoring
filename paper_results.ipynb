{
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Towards best practices for predictive process monitoring\n",
    "## By: Stijn Kas, Ivar Siccama, Peter van der Putten, Georg Krempl, Ruben Post, Sebastiaan Wiewel & Hajo Reijers\n",
    "\n",
    "This notebook contains the scripts for reproduction of the results from our paper. Performance may be better outside of a jupyter notebook, this document serves as a reference for all experiments which can be executed individually. \n",
    "\n",
    "All results are contained in this notebook, and the plots were recreated in RStudio for the final paper version, the script for which can be found in the main folder."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Imports from river, base python and custom components"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose, preprocessing, stream\n",
    "from river import tree, ensemble, naive_bayes\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numbers\n",
    "import copy\n",
    "\n",
    "from OPPM.components import *"
   ]
  },
  {
   "source": [
    "### Set directory and (re)set dataset-specific objects"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"OPPM/datasets\"\n",
    "dataset = \"BPIC_2017\"\n",
    "configs = tools.data_set(dataset, directory)\n",
    "\n",
    "label = labeling.labeler(\n",
    "    outcomes = {\"O_Cancelled\", \"O_Accepted\", \"O_Refused\"},\n",
    "    positive_outcomes = {\"O_Accepted\"},\n",
    "    feature = configs['vartypes']['activity_col'],\n",
    "    positive_label = 1,\n",
    "    negative_label = 0\n",
    ")"
   ]
  },
  {
   "source": [
    "### Configure model configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = compose.SelectType(str) | preprocessing.OneHotEncoder()\n",
    "num = compose.SelectType(numbers.Number) | preprocessing.StandardScaler()\n",
    "model_prep = (cat+num)\n",
    "\n",
    "arf = ensemble.AdaptiveRandomForestClassifier(max_depth=15, memory_estimate_period=500, max_size=25)\n",
    "hat = tree.HoeffdingAdaptiveTreeClassifier(max_depth=15, memory_estimate_period = 500, max_size = 25)\n",
    "nb = naive_bayes.GaussianNB()"
   ]
  },
  {
   "source": [
    "# Experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "| Experiment \t| Classifier \t| Encoding    \t| Time features \t| Rollback \t|\n",
    "|------------\t|------------\t|-------------\t|---------------\t|----------\t|\n",
    "| 1          \t| ARF        \t| No          \t| False         \t| False    \t|\n",
    "| 2          \t| ARF        \t| Subset      \t| True          \t| False    \t|\n",
    "| 3          \t| ARF        \t| Last state  \t| False         \t| False    \t|\n",
    "| 4          \t| ARF        \t| First state \t| False         \t| False    \t|\n",
    "| 5          \t| ARF        \t| Last state  \t| True          \t| False    \t|\n",
    "| 6          \t| ARF        \t| First state \t| True          \t| False    \t|\n",
    "| 7          \t| ARF        \t| Subset      \t| True          \t| True     \t|\n",
    "| 8          \t| ARF        \t| Last state  \t| True          \t| True     \t|\n",
    "| 9          \t| HAT        \t| Subset      \t| True          \t| False    \t|\n",
    "| 10         \t| HAT        \t| Subset      \t| True          \t| True     \t|\n",
    "| 11         \t| GNB        \t| Subset      \t| True          \t| False    \t|\n",
    "| 12         \t| GNB        \t| Subset      \t| True          \t| True     \t|\n",
    "| 13         \t| GNB        \t| Last state  \t| True          \t| False    \t|\n",
    "| 14         \t| GNB        \t| Last state  \t| True          \t| True     \t|\n",
    "| 15         \t| GNB        \t| First state \t| True          \t| False    \t|"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Experiment 1:\n",
    "#### Baseline: Adaptive Random Forest with no encoding, timefeatures or rollback\n",
    "Also a quick way to export seen list for analysis with true label\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | arf\n",
    "preds, seen = defaultdict(list), defaultdict(dict)\n",
    "data = stream.iter_csv(f\"{directory}/{dataset}.csv\", **configs['params'])\n",
    "\n",
    "for x, _ in tqdm(data):\n",
    "    case_id = x[configs['vartypes']['case_id_col']]\n",
    "    if case_id not in seen.keys():\n",
    "        if label.check(x):\n",
    "            y = label.get(x)\n",
    "            model.learn_one(x, y)\n",
    "            seen.update({case_id:y})\n",
    "        else:\n",
    "            preds[case_id].append(model.predict_proba_one(x)[label.positive_label])\n",
    "\n",
    "# Uncomment the next line(s) to write results to csv\n",
    "# pd.DataFrame.from_dict(seen, orient='index').to_csv(\"results/00_seen.csv\")\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/01_baseline.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 2:\n",
    "#### Adaptive Random Forest\n",
    "- Encoding: Custom subset\n",
    "- Time features: True\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | arf\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_subset\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/02_ARF_subset.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 3:\n",
    "#### Adaptive Random Forest\n",
    "- Encoding: Last state only \n",
    "- Time features: False\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | arf\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_last\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=False, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/03_ARF_last.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 4:\n",
    "#### Adaptive Random Forest\n",
    "- Encoding: First state only\n",
    "- Time features: False\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | arf\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_first\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=False, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/04_ARF_first.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 5:\n",
    "#### Adaptive Random Forest\n",
    "- Encoding: Last state only\n",
    "- Time features: True\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | arf\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_last\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/05_ARF_last_time.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 6:\n",
    "#### Adaptive Random Forest\n",
    "- Encoding: First state only\n",
    "- Time features: True\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | arf\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_first\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/06_ARF_first_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/98_ARF_first_time_2.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 7:\n",
    "#### Adaptive Random Forest\n",
    "- Encoding: Custom subset\n",
    "- Time features: True\n",
    "- Rollback: True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | arf\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_subset\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=True)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/07_ARF_subset_rollback.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 8:\n",
    "#### Adaptive Random Forest\n",
    "- Encoding: Last state\n",
    "- Time features: True\n",
    "- Rollback: True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | arf\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_last\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=True)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/08_ARF_last_time_rollback.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 9:\n",
    "#### Hoeffding Adaptive Tree\n",
    "- Encoding: Custom subset\n",
    "- Time features: True\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | hat\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_subset\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/09_HAT_subset.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 10:\n",
    "#### Hoeffding Adaptive Tree\n",
    "- Encoding: Custom subset\n",
    "- Time features: True\n",
    "- Rollback: True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | hat\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_subset\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=True)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/10_HAT_subset_rollback.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 11:\n",
    "#### Gaussian Naive Bayes\n",
    "- Encoding: Custom subset\n",
    "- Time features: True\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | gnb\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_subset\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/11_GNB_subset.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 12:\n",
    "#### Gaussian Naive Bayes\n",
    "- Encoding: Custom subset\n",
    "- Time features: True\n",
    "- Rollback: True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | gnb\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_subset\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=True)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/12_GNB_subset_rollback.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 13:\n",
    "#### Gaussian Naive Bayes\n",
    "- Encoding: Last state\n",
    "- Time features: True\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | gnb\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_last\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/13_GNB_last_time.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 14:\n",
    "#### Gaussian Naive Bayes\n",
    "- Encoding: Last state\n",
    "- Time features: True\n",
    "- Rollback: True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | gnb\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_last\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=True)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/14_GNB_last_rollback.csv\")"
   ]
  },
  {
   "source": [
    "#### Experiment 15:\n",
    "#### Gaussian Naive Bayes\n",
    "- Encoding: First state\n",
    "- Time features: True\n",
    "- Rollback: False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_prep) | gnb\n",
    "data, configs, timefeatures, encodings = tools.reset(\"BPIC_2017\", directory, \"BPIC_2017_first\")\n",
    "\n",
    "preds, seen, model = pipeline.OPPM(data, configs, label, model, encodings, timefeatures=timefeatures, rollback=False)\n",
    "\n",
    "# Uncomment the next line to write results to csv\n",
    "# pd.DataFrame.from_dict(preds, orient='index').to_csv(\"results/15_GNB_first_time.csv\")"
   ]
  }
 ]
}
